{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f05ed661-da3b-46f8-a681-d0bd58936ad1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%env ENV=prod\n",
    "%env ENV=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d662b4d-749d-46f0-bcf6-6f22c28f9982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# ‚ôªÔ∏è Force Reload of config.py and Supporting Modules\n",
    "# ================================================================\n",
    "import sys, importlib, os\n",
    "\n",
    "# Ensure workspace root is on sys.path\n",
    "workspace_root = \"/Workspace/Users/markholahan@pm.me/unguided-capstone-project\"\n",
    "if workspace_root not in sys.path:\n",
    "    sys.path.append(workspace_root)\n",
    "\n",
    "# Clean out cached modules\n",
    "for module_name in list(sys.modules.keys()):\n",
    "    if module_name.startswith(\"scripts\"):\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "# Optional: enforce desired environment before import\n",
    "os.environ[\"ENV\"] = os.getenv(\"ENV\", \"test\").lower()\n",
    "print(f\"üåç Reinitializing config in {os.environ['ENV'].upper()} mode\")\n",
    "\n",
    "# Reimport the package fresh\n",
    "import scripts.config as config\n",
    "importlib.reload(config)\n",
    "\n",
    "print(\"‚úÖ config.py successfully reloaded.\")\n",
    "print(f\"üîß Active environment: {config.ENV.upper()} | RUN_ID={config.RUN_ID}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35796085-be75-4306-834f-c269eaffa3a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# üß≠ Mission Control ‚Äî Capstone Step 9: \"Release the Kraken\"\n",
    "# ---------------------------------------------------------------\n",
    "# Purpose : Validate pipeline environment + configuration before full run\n",
    "# Placement: Run this FIRST in Pipeline_Runner_Notebook\n",
    "# ================================================================\n",
    "\n",
    "import scripts.config as config\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"\\n===============================================================\")\n",
    "print(\"üöÄ CAPSTONE PIPELINE ‚Äî MISSION CONTROL\")\n",
    "print(\"===============================================================\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# üåç Environment Overview\n",
    "# ---------------------------------------------------------------\n",
    "print(f\"üåé Environment Mode   : {config.ENV.upper()}\")\n",
    "print(f\"üß± Unity Catalog Mode : {'ENABLED' if config.UC_MODE else 'DISABLED'}\")\n",
    "print(f\"üè∑Ô∏è  Run ID            : {config.RUN_ID}\")\n",
    "print(f\"üí° Storage Account    : {config.STORAGE_ACCOUNT}\")\n",
    "print(f\"üì¶ Containers         : bronze={config.CONTAINER_BRONZE}, silver={config.CONTAINER_SILVER}, gold={config.CONTAINER_GOLD}, metrics={config.CONTAINER_METRICS}\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# üß± Medallion Layer Paths\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üóÇÔ∏è  Medallion Directories\")\n",
    "print(f\"ü•â Bronze Layer  ‚Üí {config.BRONZE_DIR}\")\n",
    "print(f\"ü•à Silver Layer  ‚Üí {config.SILVER_DIR}\")\n",
    "print(f\"ü•á Gold Layer    ‚Üí {config.GOLD_DIR}\")\n",
    "print(f\"üìä Metrics Layer ‚Üí {config.METRICS_DIR}\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# üé¨ TMDB Extraction Parameters\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üé¨ TMDB Extraction Parameters\")\n",
    "print(f\"   TMDB_PAGE_LIMIT        = {config.TMDB_PAGE_LIMIT}\")\n",
    "print(f\"   TMDB_MAX_RESULTS       = {config.TMDB_MAX_RESULTS}\")\n",
    "print(f\"   TMDB_REQUEST_DELAY_SEC = {config.TMDB_REQUEST_DELAY_SEC}\")\n",
    "print(f\"   TMDB_API_URL           = https://api.themoviedb.org/3/movie/popular\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# üéß DISCOGS Extraction Parameters\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üéß DISCOGS Extraction Parameters\")\n",
    "print(f\"   DISCOGS_PAGE_CAP    = {config.DISCOGS_PAGE_CAP}\")\n",
    "print(f\"   DISCOGS_PER_PAGE    = {config.DISCOGS_PER_PAGE}\")\n",
    "print(f\"   DISCOGS_SLEEP_SEC   = {config.DISCOGS_SLEEP_SEC}\")\n",
    "print(f\"   DISCOGS_MAX_TITLES  = {config.DISCOGS_MAX_TITLES}\")\n",
    "print(f\"   DISCOGS_USER_AGENT  = {config.DISCOGS_USER_AGENT}\")\n",
    "print(f\"   DISCOGS_API_URL     = https://api.discogs.com/database/search\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# üåê Network Reliability Controls\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üåê Network & API Controls\")\n",
    "print(f\"   API_TIMEOUT          = {config.API_TIMEOUT}\")\n",
    "print(f\"   API_MAX_RETRIES      = {config.API_MAX_RETRIES}\")\n",
    "print(f\"   RETRY_BACKOFF        = {config.RETRY_BACKOFF}\")\n",
    "print(f\"   MAX_PAGINATION_WARN  = {config.MAX_PAGINATION_WARN}\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# üîé Configuration Validation\n",
    "# ---------------------------------------------------------------\n",
    "warnings = []\n",
    "\n",
    "if config.TMDB_PAGE_LIMIT > config.MAX_PAGINATION_WARN:\n",
    "    warnings.append(\n",
    "        f\"‚ö†Ô∏è TMDB_PAGE_LIMIT ({config.TMDB_PAGE_LIMIT}) exceeds MAX_PAGINATION_WARN ({config.MAX_PAGINATION_WARN})\"\n",
    "    )\n",
    "if config.DISCOGS_PAGE_CAP > config.MAX_PAGINATION_WARN:\n",
    "    warnings.append(\n",
    "        f\"‚ö†Ô∏è DISCOGS_PAGE_CAP ({config.DISCOGS_PAGE_CAP}) exceeds MAX_PAGINATION_WARN ({config.MAX_PAGINATION_WARN})\"\n",
    "    )\n",
    "\n",
    "if warnings:\n",
    "    print(\"üö® CONFIG WARNINGS DETECTED:\")\n",
    "    for w in warnings:\n",
    "        print(f\"   {w}\")\n",
    "else:\n",
    "    print(\"‚úÖ Configuration check passed ‚Äî all limits within safety bounds.\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# üß© Step Preview\n",
    "# ---------------------------------------------------------------\n",
    "ACTIVE_STEPS = [1, 2, 3, 4, 5]\n",
    "print(f\"üß© Steps to Run : {ACTIVE_STEPS}\")\n",
    "print(f\"üßæ Output Format: Parquet (Spark ‚Üí ADLS / UC passthrough)\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# üß† Debug Context Snapshot\n",
    "# ---------------------------------------------------------------\n",
    "print(\"üß† Current Path Configuration:\")\n",
    "pprint(config.get_paths_dict())\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "print(\"‚úÖ Mission Control initialized ‚Äî ready for launch.\")\n",
    "print(\"===============================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae424d26-387d-4054-839a-5e11853a5a53",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"status\":261},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762319204767}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "#  Pipeline_Runner.py ‚Äî v4.0 (Databricks / Mount-less / Config-Driven)\n",
    "#  ---------------------------------------------------------------\n",
    "#  Purpose : Execute full ETL pipeline (Steps 01‚Äì05)\n",
    "#  Runtime : Databricks 16.4 LTS (Unity Catalog)\n",
    "#  Author  : M. Holahan\n",
    "# ================================================================\n",
    "\n",
    "# COMMAND ----------\n",
    "# ‚úÖ Environment bootstrap\n",
    "!pip install -q adlfs fsspec rapidfuzz\n",
    "\n",
    "import sys\n",
    "import inspect\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "import scripts.config as config\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Ensure Spark context exists (Databricks sometimes resets)\n",
    "try:\n",
    "    spark = config.spark\n",
    "except AttributeError:\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# ================================================================\n",
    "# üåç Environment Diagnostics\n",
    "# ================================================================\n",
    "print(\"\\n===============================================================\")\n",
    "print(\"üöÄ CAPSTONE PIPELINE ‚Äî RUNNER (v4.0)\")\n",
    "print(\"===============================================================\")\n",
    "print(f\"üåé Environment Mode     : {config.ENV.upper()}\")\n",
    "print(f\"üß± Unity Catalog Mode   : {'ENABLED' if config.UC_MODE else 'DISABLED'}\")\n",
    "print(f\"üè∑Ô∏è  Run ID              : {config.RUN_ID}\")\n",
    "print(f\"üíæ Storage Account      : {config.STORAGE_ACCOUNT}\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(f\"ü•â Bronze Layer  ‚Üí {config.BRONZE_DIR}\")\n",
    "print(f\"ü•à Silver Layer  ‚Üí {config.SILVER_DIR}\")\n",
    "print(f\"ü•á Gold Layer    ‚Üí {config.GOLD_DIR}\")\n",
    "print(f\"üìä Metrics Layer ‚Üí {config.METRICS_DIR}\")\n",
    "print(\"===============================================================\\n\")\n",
    "\n",
    "# ================================================================\n",
    "# üß© Import pipeline steps\n",
    "# ================================================================\n",
    "from scripts.extract_spark_tmdb import Step01ExtractSparkTMDB\n",
    "from scripts.extract_spark_discogs import Step02ExtractSparkDiscogs\n",
    "from scripts.prepare_tmdb_discogs_candidates import Step03PrepareTMDBDiscogsCandidates\n",
    "from scripts.validate_schema_alignment import Step04ValidateSchemaAlignment\n",
    "#from scripts.match_and_enrich import Step05MatchAndEnrichDBX\n",
    "\n",
    "PIPELINE_STEPS = {\n",
    "    1: Step01ExtractSparkTMDB,\n",
    "    2: Step02ExtractSparkDiscogs,\n",
    "    3: Step03PrepareTMDBDiscogsCandidates,\n",
    "    4: Step04ValidateSchemaAlignment,\n",
    "    #5: Step05MatchAndEnrichDBX,\n",
    "}\n",
    "\n",
    "# ================================================================\n",
    "# ‚öôÔ∏è Parameter block\n",
    "# ================================================================\n",
    "ACTIVE_STEPS = [2]     # adjust as needed for partial runs\n",
    "ROW_LIMIT = None                    # optional debugging limit\n",
    "\n",
    "print(f\"üß© Active Steps  : {ACTIVE_STEPS}\")\n",
    "print(f\"üìä Metrics Path  : {config.layer_path('metrics', 'pipeline_summary')}\\n\")\n",
    "\n",
    "# ================================================================\n",
    "# üöÄ Execute pipeline with structured logging\n",
    "# ================================================================\n",
    "results = []\n",
    "\n",
    "for step_no in ACTIVE_STEPS:\n",
    "    StepClass = PIPELINE_STEPS[step_no]\n",
    "    module_name = StepClass.__module__\n",
    "\n",
    "    # Safely reload module (helps during development / notebook runs)\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "\n",
    "    step_name = StepClass.__name__\n",
    "    print(f\"\\nüöÄ Running Step {step_no}: {step_name}\")\n",
    "    t0 = time.time()\n",
    "    status = \"success\"\n",
    "\n",
    "    try:\n",
    "        step = StepClass()\n",
    "        sig = inspect.signature(step.run)\n",
    "        kwargs = {\"limit\": ROW_LIMIT} if \"limit\" in sig.parameters else {}\n",
    "        df_out = step.run(**kwargs)\n",
    "    except Exception as e:\n",
    "        status = f\"failed: {type(e).__name__}\"\n",
    "        print(f\"‚ö†Ô∏è Step {step_no} ({step_name}) failed: {e}\")\n",
    "        df_out = None\n",
    "\n",
    "    duration = round(time.time() - t0, 2)\n",
    "    results.append({\n",
    "        \"step\": step_no,\n",
    "        \"name\": step_name,\n",
    "        \"duration_sec\": duration,\n",
    "        \"status\": status\n",
    "    })\n",
    "    print(f\"‚úÖ Step {step_no} completed ‚Üí {status.upper()} in {duration}s\")\n",
    "\n",
    "# ================================================================\n",
    "# üìä Summary logging\n",
    "# ================================================================\n",
    "summary_df = pd.DataFrame(results)\n",
    "display(summary_df)\n",
    "\n",
    "summary_json = summary_df.to_json(orient=\"records\", indent=2)\n",
    "print(f\"\\nüìä Pipeline Summary:\\n{summary_json}\")\n",
    "\n",
    "# Write to metrics layer via config helpers\n",
    "summary_output = config.layer_path(\"metrics\", \"pipeline_summary\")\n",
    "\n",
    "try:\n",
    "    import fsspec\n",
    "    fs = fsspec.filesystem(\"abfss\", account_name=config.STORAGE_ACCOUNT, anon=False)\n",
    "    with fs.open(f\"{summary_output}/summary_{config.RUN_ID}.json\", \"w\") as f:\n",
    "        f.write(summary_json)\n",
    "    print(f\"üì§ Summary uploaded ‚Üí {summary_output}/summary_{config.RUN_ID}.json\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not upload summary to ADLS: {e}\")\n",
    "\n",
    "print(f\"\\nüèÅ Pipeline execution complete in {config.ENV.upper()} mode.\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8724313004351644,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Pipeline_Runner_Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
