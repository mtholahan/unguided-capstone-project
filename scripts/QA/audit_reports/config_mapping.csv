file,line,value,kind,context,status,proposed_name,best_match,similarity_score
step_00_acquire_musicbrainz.py,37,1024.0,unknown,"chunk_size = max(1024, CHUNK_SIZE)",New constant suggested,MAGIC_CONST_VAL,,0.0
step_00_acquire_musicbrainz.py,121,6.0,threshold,if len(parts) < 6:,New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_01_audit_raw.py,46,1000000.0,row limit,csv.field_size_limit(1_000_000),New constant suggested,ROW_LIMIT_VAL,,0.0
step_01_audit_raw.py,61,30.0,unknown,"for row in self.progress_iter(reader, desc=tsv_path.name[:30], unit=""row"", leave=False):",New constant suggested,MAGIC_CONST_VAL,,0.0
step_02_cleanse_tsv.py,123,20.0,row limit,sample = df.head(20),New constant suggested,ROW_LIMIT_VAL,,0.0
step_02_cleanse_tsv.py,143,3.0,unknown,"metrics[""release_year_coverage""] = round(coverage, 3)",New constant suggested,MAGIC_CONST_VAL,,0.0
step_03b_rehydrate_guids.py,73,6.0,unknown,"ac = pd.read_csv(ac_path, sep=""\t"", header=None, low_memory=False, usecols=[0, 6])",New constant suggested,MAGIC_CONST_VAL,,0.0
step_03b_rehydrate_guids.py,102,100.0,unknown,"coverage_rg = release[""release_group_gid""].notna().mean() * 100",New constant suggested,MAGIC_CONST_VAL,,0.0
step_03b_rehydrate_guids.py,116,10.0,unknown,].head(10),New constant suggested,MAGIC_CONST_VAL,,0.0
step_03b_rehydrate_guids.py,122,40.0,unknown,"f""   id={row.get('id', '?')} | name={str(row.get('name', ''))[:40]} | """,New constant suggested,MAGIC_CONST_VAL,,0.0
step_03b_rehydrate_guids.py,130,2.0,unknown,"""coverage_release_group"": round(coverage_rg, 2),",New constant suggested,MAGIC_CONST_VAL,,0.0
step_04_mb_full_join.py,76,2.0,threshold,st_map = {r[0]: r[1] for r in rgst_rows if len(r) >= 2},New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_04_mb_full_join.py,122,5.0,threshold,if len(row) < 5:,New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_04_mb_full_join.py,126,3.0,threshold,artist_credit_id = row[3] if len(row) > 3 else None,New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_04_mb_full_join.py,127,4.0,threshold,release_group_id = row[4] if len(row) > 4 else None,New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_04_mb_full_join.py,146,10.0,threshold,if len(soundtrack_samples) < 10 or random.random() < 0.001:,New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_04_mb_full_join.py,146,0.001,threshold,if len(soundtrack_samples) < 10 or random.random() < 0.001:,New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_04_mb_full_join.py,165,100.0,row limit,soundtrack_pct = (soundtrack_count / joined_rows * 100) if joined_rows else 0,New constant suggested,ROW_LIMIT_VAL,,0.0
step_04_mb_full_join.py,180,5.0,row limit,for row in soundtrack_samples[:5]:,New constant suggested,ROW_LIMIT_VAL,,0.0
step_05_filter_soundtracks_enhanced.py,64,13.0,threshold,if len(row) < 13:,New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_05_filter_soundtracks_enhanced.py,66,4.0,unknown,rgid = row[4].strip(),New constant suggested,MAGIC_CONST_VAL,,0.0
step_05_filter_soundtracks_enhanced.py,159,0.02,row limit,"subset_fraction = getattr(self.config, ""SAMPLE_FRACTION"", 0.02)",New constant suggested,ROW_LIMIT_VAL,,0.0
step_05_filter_soundtracks_enhanced.py,161,42.0,row limit,"sample = df.sample(frac=subset_fraction, random_state=42)",New constant suggested,ROW_LIMIT_VAL,,0.0
step_06_fetch_tmdb.py,31,1000.0,row limit,self.max_movies = 1000  # overridden by ROW_LIMIT or Golden Mode,New constant suggested,ROW_LIMIT_VAL,,0.0
step_06_fetch_tmdb.py,32,500.0,unknown,self.max_pages = 500,New constant suggested,MAGIC_CONST_VAL,,0.0
step_06_fetch_tmdb.py,96,20.0,unknown,"movies, page, per_page = [], 1, 20",New constant suggested,MAGIC_CONST_VAL,,0.0
step_06_fetch_tmdb.py,213,10.0,timeout,"r = self.session.get(url, params=params, timeout=10)",New constant suggested,TIMEOUT_SECONDS_VAL,,0.0
step_07_prepare_tmdb_input.py,77,1900.0,threshold,if not (1900 <= yr <= 2025):,New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_07_prepare_tmdb_input.py,77,2025.0,threshold,if not (1900 <= yr <= 2025):,New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_07_prepare_tmdb_input.py,113,1900.0,unknown,"(df_tmdb[""year""].between(1900, 2025))",New constant suggested,MAGIC_CONST_VAL,,0.0
step_07_prepare_tmdb_input.py,113,2025.0,unknown,"(df_tmdb[""year""].between(1900, 2025))",New constant suggested,MAGIC_CONST_VAL,,0.0
step_08_match_instrumented.py,72,1.5,timing,time.sleep(1.5 * (attempt + 1)),New constant suggested,API_THROTTLE_SECONDS_VAL,,0.0
step_08_match_instrumented.py,148,100.0,threshold,"""score"": 100,",New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_08_match_instrumented.py,185,0.7,threshold,"scorer=lambda a, b, **_: int(0.7 * fuzz.token_set_ratio(a, b) + 0.3 * fuzz.partial_ratio(a, b)),",New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_08_match_instrumented.py,185,0.3,threshold,"scorer=lambda a, b, **_: int(0.7 * fuzz.token_set_ratio(a, b) + 0.3 * fuzz.partial_ratio(a, b)),",New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_08_match_instrumented.py,243,105.0,threshold,"pd.cut(pd.Series([m[""score""] for m in matches]), bins=np.arange(0, 105, 5))",New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_09_apply_rescues.py,14,90.0,threshold,"def __init__(self, name=""Step 09: Apply Manual Rescues (Enhanced & Polished)"", threshold: float = 90.0):",New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
step_10_enrich_tmdb.py,27,0.25,timing,self.sleep_time = 0.25  # polite throttle between API calls,New constant suggested,API_THROTTLE_SECONDS_VAL,,0.0
step_10_enrich_tmdb.py,42,1.5,unknown,"def _safe_get(self, url: str, params: dict, retries: int = 3, backoff: float = 1.5):",New constant suggested,MAGIC_CONST_VAL,,0.0
step_10b_coverage_audit.py,17,0.85,threshold,"def __init__(self, name=""Step 10B: OST Coverage Audit"", similarity_threshold=0.85):",New constant suggested,FUZZ_THRESHOLD_VAL,,0.0
