# Unguided Capstone ‚Äì TMDB + Discogs Data Pipeline

**Version 3.2.0  |  Step 10 ‚Äì Build Monitoring Dashboard  |  Status:** üü© Stable  |  Branch: `step10-submission`

**Mentor:** Akhil

------

## üß≠ Context Recap

Building on Step 9‚Äôs production deployment, this phase introduced real-time monitoring and diagnostics for all Azure components. Using Azure Log Analytics and Application Insights, telemetry from the Function App, Storage Account, and Databricks jobs was centralized into a custom dashboard visualizing key operational metrics.

------

## üéØ Project Overview (Step 10 ‚Äì Monitoring Dashboard)

This release extends the **production-ready TMDB + Discogs Medallion data pipeline** with an end-to-end **monitoring and observability layer**.
 The new **Azure Log Analytics‚Äìbased dashboard** consolidates telemetry from Azure Databricks, Data Lake Storage Gen2, and Function Apps to provide real-time visibility into pipeline health, resource utilization, and cost efficiency.

Operational data is aggregated across the **Bronze ‚Üí Silver ‚Üí Gold** layers and visualized through custom Kusto queries, enabling rapid detection of performance degradation and anomalous blob or compute activity.
 The dashboard delivers proactive insights that ensure the pipeline continues to meet reliability and scalability expectations in production.

------

## üìö Data Sources

- **TMDB API v3:** Movie metadata
- **Discogs API:** Artist and record release catalog

Combined, these sources enable multi-domain analytics linking film and music metadata. During production runs, data ingestion handled full API pagination and adaptive rate limiting to prevent throttling.

------

## ‚öôÔ∏è Production Objectives

- Deploy finalized PySpark ETL to Azure Databricks cluster at scale
- Persist outputs to **Azure Data Lake Gold** container in `.parquet` format
- Validate lineage, schema, and runtime metrics through automated JSON audit logs
- Document architecture, runtime, and deployment topology per rubric requirements

------

## üèóÔ∏è Production Architecture (Updated)

The final architecture remains consistent with Step 7's theoretical model, incorporating optimized cluster sizing and Azure cost controls.)



![ungcap_architecture_step9](assets/ungcap_architecture_step9-1762572407799-5.png)

> [!NOTE]
>
> The production configuration preserves the logical topology defined in Step 7 but introduces modular Bicep definitions, Databricks Runtime 16 LTS, and integration with **Azure Monitor + Log Analytics**. These updates improve observability, maintainability, and cost governance.



### **Key Components**

| Layer          | Azure Service                  | Purpose                          |
| -------------- | ------------------------------ | -------------------------------- |
| **Bronze**     | ADLS Container `raw/`          | Raw TMDB + Discogs ingestion     |
| **Silver**     | ADLS Container `intermediate/` | Cleaned and standardized records |
| **Gold**       | ADLS Container `gold/`         | Matched, enriched outputs        |
| **Compute**    | Databricks Cluster             | PySpark execution at scale       |
| **Monitoring** | Azure Log Analytics            | Step 10 dashboard foundation     |



### Azure Databricks Workspace

![databricks_workspace_overview](assets/databricks_workspace_overview-1762572073529-1.png)



### Azure Resources

![azure_resource_groups](assets/azure_resource_groups-1762572147247-1.png)



### üìò **Azure Resource Organization**

| Resource Group                    | Purpose                       | Key Resources                             |
| --------------------------------- | ----------------------------- | ----------------------------------------- |
| **`rg-unguidedcapstone`**         | Core production workspace     | `ungcap-dbws`, `ungcap-kv`, `ungcap-vnet` |
| **`rg-unguidedcapstone-test`**    | Step 9 validation environment | `ungcapstor01`, `ungcapkv01`              |
| **`rg-unguidedcapstone-managed`** | Databricks-managed compute    | Managed by Azure                          |
| **`NetworkWatcherRG`**            | Monitoring workspace          | Diagnostic use only                       |
| **`capstone-databricks-managed`** | Legacy prototype group        | Archived                                  |

> [!NOTE]
> Production workloads execute entirely in `rg-unguidedcapstone`, using managed identities for secure cross-RG access to storage and Key Vault resources.

------



## üìä Monitoring Dashboard Overview

The Step 10 monitoring system integrates **Azure Monitor**, **Log Analytics**, and **Application Insights** to provide unified visibility.

**Dashboard Name:** `UnguidedCap-Monitor`
**Workspace:** `ungcap-logws`
**Location:** East US 2

### Tracked Metrics
| Category              | Metric                                       | Description                               |
| --------------------- | -------------------------------------------- | ----------------------------------------- |
| Storage Performance   | `BlobCapacity`, `E2ELatency`, `Transactions` | Throughput & latency per container        |
| Resource Usage        | `CPU %`, `Memory %`, `IOPS`                  | VM and Databricks node utilization        |
| Blob Access           | `Read Ops`, `Write Ops`, `Delete Ops`        | Operation frequency over time             |
| Function App Activity | `Requests`, `Failures`, `Duration (ms)`      | Health & SLA compliance                   |
| Cost Insights         | `Daily Cost Estimate`                        | Derived from Azure Cost Management export |

Snapshots of the dashboard tiles are stored under `assets/`.



> [!NOTE]
>
> Mentor Access: Azure Log Analytics Dashboard ‚Äì *Shared via Azure RBAC (Reader role)*
> Workspace: `ungcap-logws`
> Dashboard: `UnguidedCapstone Monitor`
> Location: East US 2
> Access granted to: Akhil (Springboard mentor)



## üöÄ Execution Procedure

1. Attach to production cluster (`capstone-prod-cluster`).
2. Configure parameters as appropriate with `config.py`
3. Execute `Pipeline_Runner.ipynb` to process complete TMDB + Discogs dataset.
4. Validate Gold-layer outputs in `wasbs://gold@<storage>.blob.core.windows.net/`.
5. Confirm lineage and runtime logs in `/data/metrics/`.

### Production Run Highlight Log

![data_pipeline_curated_production_log](assets/data_pipeline_curated_production_log-1762572316500-3.png)



------

## üìä Pipeline Execution Metrics

| Metric                      | Value                                       |
| --------------------------- | ------------------------------------------- |
| **Total Processed Records** | 39,718 (10,000 TMDB + 29,718 Discogs)       |
| **Strong Matches**          | 1,709                                       |
| **Duration (min)**          | 26:23                                       |
| **Cluster Type**            | Standard Databricks 16 LTS (2-node)         |
| **Cost Optimization**       | Auto-terminate, spot VMs, ephemeral compute |

### Medallion Lineage Summary

| Step               | Layer  | Records Out | Duration (sec) | Output                  |
| ------------------ | ------ | ----------- | -------------- | ----------------------- |
| Extract TMDB       | Bronze | 10,000      | 288            | raw/tmdb                |
| Extract Discogs    | Bronze | 29,718      | 532            | raw/discogs             |
| Prepare Candidates | Silver | 3,605       | 84             | intermediate/candidates |
| Match & Enrich     | Gold   | 1,709       | <1             | gold/matches            |

> **Total Match Rate:** 47.4 %
>  **Run ID:** `20251107T023645`

------

## üí∞ Cost Optimization & Resource Management

Production clusters are ephemeral by design ‚Äî automatically terminated post-run.
Azure cost analysis shows 78% cost reduction through use of **Standard_DS3_v2** node class, short-lived job clusters, and active resource cleanup post-deployment.

------

## üìÇ Repository Structure (Step 9 ‚Äì Production Deployment)

```
unguided-capstone-project/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ _databricks.yml
‚îú‚îÄ‚îÄ architecture/
‚îÇ ‚îî‚îÄ‚îÄ diagrams/
‚îú‚îÄ‚îÄ assets/
‚îÇ ‚îî‚îÄ‚îÄ Azure main.bicep Orchestrator What-If Output.png
‚îú‚îÄ‚îÄ config.json
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îú‚îÄ‚îÄ cache/
‚îÇ ‚îú‚îÄ‚îÄ intermediate/
‚îÇ ‚îú‚îÄ‚îÄ logs/
‚îÇ ‚îú‚îÄ‚îÄ metrics/
‚îÇ ‚îú‚îÄ‚îÄ mock/
‚îÇ ‚îú‚îÄ‚îÄ processed/
‚îÇ ‚îú‚îÄ‚îÄ raw/
‚îÇ ‚îî‚îÄ‚îÄ validation/
‚îú‚îÄ‚îÄ evidence/
‚îÇ ‚îî‚îÄ‚îÄ Azure main.bicep Orchestrator What-If Output.png
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ ‚îú‚îÄ‚îÄ databricks.bicep
‚îÇ ‚îú‚îÄ‚îÄ functionapp.bicep
‚îÇ ‚îú‚îÄ‚îÄ keyvault.bicep
‚îÇ ‚îú‚îÄ‚îÄ main.bicep
‚îÇ ‚îú‚îÄ‚îÄ monitoring.bicep
‚îÇ ‚îú‚îÄ‚îÄ naming_conventions.md
‚îÇ ‚îú‚îÄ‚îÄ storage_account.bicep
‚îÇ ‚îú‚îÄ‚îÄ ungcap-step8-test.json
‚îÇ ‚îî‚îÄ‚îÄ vnet.bicep
‚îú‚îÄ‚îÄ logs/
‚îÇ ‚îú‚îÄ‚îÄ cleanup.log
‚îÇ ‚îú‚îÄ‚îÄ pipeline.log
‚îÇ ‚îî‚îÄ‚îÄ validation/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ ‚îú‚îÄ‚îÄ Data_Inspection_Notebook.ipynb
‚îÇ ‚îú‚îÄ‚îÄ Pipeline_Runner_Notebook.ipynb
‚îÇ ‚îî‚îÄ‚îÄ Testing_Notebook.ipynb
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ rebuild_venv.sh
‚îú‚îÄ‚îÄ requirements_cluster.txt
‚îú‚îÄ‚îÄ requirements_locked.txt
‚îú‚îÄ‚îÄ requirements_stable.txt
‚îú‚îÄ‚îÄ scripts/
‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îú‚îÄ‚îÄ pycache/
‚îÇ ‚îú‚îÄ‚îÄ base_step.py
‚îÇ ‚îú‚îÄ‚îÄ bootstrap.py
‚îÇ ‚îú‚îÄ‚îÄ config.py
‚îÇ ‚îú‚îÄ‚îÄ extract_spark_discogs.py
‚îÇ ‚îú‚îÄ‚îÄ extract_spark_tmdb.py
‚îÇ ‚îú‚îÄ‚îÄ inventory_pipeline_outputs.py
‚îÇ ‚îú‚îÄ‚îÄ main.py
‚îÇ ‚îú‚îÄ‚îÄ match_and_enrich.py
‚îÇ ‚îú‚îÄ‚îÄ prepare_tmdb_discogs_candidates.py
‚îÇ ‚îú‚îÄ‚îÄ tests/
‚îÇ ‚îú‚îÄ‚îÄ utils.py
‚îÇ ‚îú‚îÄ‚îÄ utils_schema.py
‚îÇ ‚îî‚îÄ‚îÄ validate_schema_alignment.py
‚îú‚îÄ‚îÄ slides/
‚îÇ ‚îî‚îÄ‚îÄ Step10_Presentation.pptx
‚îî‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ abfss:/
‚îú‚îÄ‚îÄ conftest.py
‚îú‚îÄ‚îÄ test_pipeline_config.py
‚îú‚îÄ‚îÄ test_report.txt
‚îî‚îÄ‚îÄ test_spark_session.py
```

------

## üñºÔ∏è Slide Deck Integration

[View Slide Deck ‚Üí Step10_Presentation.pptx](slides/Step10_Presentation.pptx)

This presentation summarizes:

- Design and implementation of the **Azure Log Analytics monitoring dashboard**
- Rationale for **metric selection** (Storage Performance, Resource Usage, Blob Access Operations, Function App Activity)
- Examples of **custom Kusto queries** and visualization layouts used in the dashboard

------

> ‚ÄúPipelines end, but data flows on.‚Äù
